# ðŸš€ LLM-on-AWS Project

This project deploys a backend application using GitHub Actions CI/CD pipelines, Docker, Kubernetes, and Terraform on AWS. The pipelines handle building, pushing, deploying, and destroying infrastructure and application resources automatically.

---

## âš™ï¸ Initial Terraform Backend Setup

Before doing anything else in this project, you must first create your Terraform S3 backend and DynamoDB lock table using the script below.

```bash
#!/bin/bash

# ======= CONFIGURATION ========
REGION="us-east-1"
BUCKET_NAME="ttf-remote-backend-state-4286"
DYNAMO_TABLE="terraform-locks"
STATE_KEY="dev/terraform.tfstate"
# ==============================

echo "ðŸ”§ Creating S3 bucket: $BUCKET_NAME"
if [ "$REGION" = "us-east-1" ]; then
  aws s3api create-bucket \
    --bucket "$BUCKET_NAME" \
    --region "$REGION"
else
  aws s3api create-bucket \
    --bucket "$BUCKET_NAME" \
    --region "$REGION" \
    --create-bucket-configuration LocationConstraint="$REGION"
fi

echo "â³ Waiting for bucket to exist..."
until aws s3api head-bucket --bucket "$BUCKET_NAME" 2>/dev/null; do
  sleep 2
done

echo "ðŸ” Enabling encryption on bucket"
aws s3api put-bucket-encryption \
  --bucket "$BUCKET_NAME" \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "AES256"
      }
    }]
  }'

echo "ðŸ“¦ Enabling versioning on bucket"
aws s3api put-bucket-versioning \
  --bucket "$BUCKET_NAME" \
  --versioning-configuration Status=Enabled

echo "ðŸ—„ï¸ Creating DynamoDB table: $DYNAMO_TABLE"
aws dynamodb create-table \
  --table-name "$DYNAMO_TABLE" \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST 2>/dev/null

echo "âœ… Done! Terraform backend infrastructure is ready."
```

---

## ðŸ“ Project Structure

```text
project/
â”œâ”€â”€ .github/workflows/          # GitHub Actions pipelines
â”‚   â”œâ”€â”€ build_push.yml          # Builds & pushes Docker image
â”‚   â”œâ”€â”€ k8s_deploy.yml          # Deploys app to Kubernetes
â”‚   â”œâ”€â”€ terraform_deployment.yml# Provisions AWS infrastructure
â”‚   â””â”€â”€ terraform_destroy.yml   # Destroys AWS infrastructure
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ backend/                # Python Flask backend
â”‚   â”‚   â”œâ”€â”€ app.py              # Main application
â”‚   â”‚   â””â”€â”€ config.py           # App config
â”‚   â””â”€â”€ Dockerfile              # Containerize app
â”œâ”€â”€ infra/                      # Terraform code
â”‚   â”œâ”€â”€ main.tf                 # Terraform resources
â”‚   â””â”€â”€ variables.tf            # Terraform variables
```

---

## ðŸ” GitHub Secrets Used

| Secret Name               | Description                                 |
|--------------------------|---------------------------------------------|
| `AWS_ACCESS_KEY_ID`      | AWS access key to deploy infrastructure     |
| `AWS_SECRET_ACCESS_KEY`  | AWS secret access key                       |
| `AWS_REGION`             | AWS region (e.g. `us-east-1`)               |
| `ECR_REPOSITORY`         | Name of the ECR repository                  |
| `KUBE_CONFIG_DATA`       | Base64 encoded Kubeconfig for cluster auth  |

---

## âš™ï¸ CI/CD Pipelines Overview

- `build_push.yml`: Builds Docker image and pushes to ECR
- `terraform_deployment.yml`: Provisions AWS infra via Terraform
- `terraform_destroy.yml`: Destroys AWS infra
- `k8s_deploy.yml`: Deploys the app to Kubernetes

---

## ðŸ’» Running Locally

### Prerequisites:
- Docker
- Python 3
- AWS CLI (configured)
- Terraform
- kubectl

### Run the App Locally

```bash
cd app
docker build -t llm:v1 .
docker run -p 8080:8080 llm:v1
```

### Deploy Infrastructure

```bash
cd infra
terraform init
terraform apply -auto-approve
```

### Deploy to Kubernetes

```bash
kubectl apply -f k8s/
```

---

## ðŸš€ GitHub Actions Triggers

Use these commit messages when pushing to `main`:

- `terraform apply`
- `terraform destroy`
- `k8s deploy`

---

## ðŸ§¼ Tear Down Infrastructure

```bash
cd infra
terraform destroy -auto-approve
```

---

## ðŸ“Š Monitoring with Prometheus & Grafana

### Prerequisites

- EKS cluster configured with `kubectl`
- Helm installed

### 1. Add Repositories

```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
```

### 2. Install Prometheus Stack

```bash
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace
```

### 3. Install Grafana

```bash
helm install grafana grafana/grafana \
  --namespace monitoring
```

### 4. Patch Grafana Service (LoadBalancer)

```bash
kubectl patch svc prometheus-grafana \
  -n monitoring \
  --type merge \
  -p '{
    "spec": {
      "type": "LoadBalancer",
      "ports": [
        {
          "name": "http",
          "protocol": "TCP",
          "port": 80,
          "targetPort": 3000
        }
      ]
    }
  }'
```

### 5. Get Grafana Password

```bash
kubectl get secret --namespace monitoring prometheus-grafana \
  -o jsonpath="{.data.admin-password}" | base64 --decode && echo
```

### 6. Test Prometheus Access

```bash
kubectl exec -n monitoring -it $(kubectl get pod -n monitoring -l app.kubernetes.io/name=grafana -o jsonpath="{.items[0].metadata.name}") -- curl -s http://prometheus-kube-prometheus-prometheus.monitoring.svc.cluster.local:9090
```

### 7. Add Prometheus as a Grafana Data Source

Use this URL:

```
http://prometheus-kube-prometheus-prometheus.monitoring.svc.cluster.local:9090
```

---

### 8. Import Grafana Dashboards

- Go to **Create â†’ Import**
- Use IDs from https://grafana.com/grafana/dashboards/

---

## ðŸ“ˆ Kubernetes Metrics Server

Install Metrics Server to enable resource metrics:

```bash
kubectl apply -f https://raw.githubusercontent.com/techiescamp/kubeadm-scripts/main/manifests/metrics-server.yaml
```

> Version: `v0.7.1`